{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e820243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import AveragePooling1D,Conv1D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold \n",
    "from scipy.spatial.distance import euclidean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59056469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold values: [0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n",
      "Total threshold values: 21\n"
     ]
    }
   ],
   "source": [
    "# Threshold values for all metrics (0 to 1 with 0.05 increments)\n",
    "threshold_values = np.arange(0, 1.05, 0.05)\n",
    "print(f\"Threshold values: {threshold_values}\")\n",
    "print(f\"Total threshold values: {len(threshold_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b553682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese Network Implementation \n",
    "num_classes = 9\n",
    "epochs = 20\n",
    " \n",
    "def euclid_dis(vects):\n",
    "  x,y = vects\n",
    "  sum_square = K.sum(K.square(x-y), axis=1, keepdims=True)\n",
    "  return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    " \n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    " \n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true=tf.cast(y_true, tf.float32)\n",
    "    y_pred=tf.cast(y_pred, tf.float32)\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs_new3(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    for d in range(num_classes):\n",
    "        n=min([len(digit_indices[d])]) -1\n",
    "        for i in range(n):\n",
    "            randomIndiceTrue=-1\n",
    "            while True:\n",
    "                if randomIndiceTrue != i:\n",
    "                    break\n",
    "                else:\n",
    "                    randomIndiceTrue = random.randrange(0, min([len(digit_indices[d])]))\n",
    "            \n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][randomIndiceTrue]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            \n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            \n",
    "            randomIndiceFalse = random.randrange(0, min([len(digit_indices[dn])]))\n",
    "            \n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][randomIndiceFalse]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1,0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "def create_base_net_new2(input_shape):\n",
    "    height=439\n",
    "    depth=1\n",
    "    num_classes=9\n",
    "    input = Input(shape = input_shape)\n",
    "    x = Reshape((height, depth))(input)\n",
    "    x = Conv1D(12, 3, strides=1, padding='valid', activation='relu')(x)\n",
    "    x = AveragePooling1D(3)(x)\n",
    "    x = Conv1D(8, 3, strides=1, padding='valid', activation='relu')(x)\n",
    "    x = AveragePooling1D(3)(x)\n",
    "    x = Conv1D(6, 3, strides=1, padding='valid', activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation = 'relu')(x)\n",
    "    model = Model(input, x)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_f1(y_true, y_pred): \n",
    "    pred = K.cast(y_pred < 0.5, y_true.dtype)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_val\n",
    "\n",
    "def compute_f1(y_true, y_pred):\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    pred=pred*1\n",
    "    TN,FP,FN,TP=confusion_matrix(y_true, pred).ravel()\n",
    "\n",
    "    recall = TP/(TP+FN)\n",
    "    precision=TP/(TP+FP)\n",
    "\n",
    "    f1_val = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_val\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3b9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_f1(t_pairs, t_y, cosine_threshold=0.4):\n",
    "    cTP=0\n",
    "    cFP=0\n",
    "    cFN=0\n",
    "    cTN=0\n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        cos_result=cosine_similarity(t_pairs[i, 0].reshape(1, -1), t_pairs[i, 1].reshape(1, -1))\n",
    "        if t_y[i]==1 and cos_result>=cosine_threshold:\n",
    "            cTP=cTP+1\n",
    "        elif t_y[i]!=1 and cos_result>=cosine_threshold:\n",
    "            cFP=cFP+1\n",
    "        elif t_y[i]==1 and cos_result<cosine_threshold:\n",
    "            cFN=cFN+1\n",
    "        elif t_y[i]!=1 and cos_result<cosine_threshold:\n",
    "            cTN=cTN+1\n",
    "        \n",
    "    recall = cTP/(cTP+cFN) if (cTP+cFN) > 0 else 0\n",
    "    \n",
    "    precision=cTP/(cTP+cFP) if (cTP+cFP) > 0 else 0\n",
    "    \n",
    "    if (precision+recall) == 0:\n",
    "        f1_cosine_val = 0\n",
    "    else:\n",
    "        f1_cosine_val = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_cosine_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e671fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(point1, point2):\n",
    "    return np.sum(np.abs(point1 - point2))\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def compute_manhattan_f1(t_pairs, t_y, manhattan_threshold=0.85):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    # Max-Min Normalizasyonu\n",
    "    t_pairs_normalized = np.array([min_max_normalize(pair) for pair in t_pairs])\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        result = manhattan_distance(t_pairs_normalized[i, 0], t_pairs_normalized[i, 1])\n",
    "        if t_y[i] == 1 and result >= manhattan_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result >= manhattan_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result < manhattan_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result < manhattan_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_manhattan_val = 0\n",
    "    else:\n",
    "        f1_manhattan_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_manhattan_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d286bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def compute_euclidean_f1(t_pairs, t_y, euclidean_threshold=0.7):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    # Max-Min Normalizasyonu\n",
    "    t_pairs_normalized = np.array([min_max_normalize(pair) for pair in t_pairs])\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        result = euclidean_distance(t_pairs_normalized[i, 0], t_pairs_normalized[i, 1])\n",
    "        if t_y[i] == 1 and result >= euclidean_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result >= euclidean_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result < euclidean_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result < euclidean_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_euclidean_val = 0\n",
    "    else:\n",
    "        f1_euclidean_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_euclidean_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5498db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import canberra\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def compute_canberra_f1(t_pairs, t_y, canberra_threshold=0.85):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        # Apply Max-Min normalization to each pair\n",
    "        t_pair_normalized = np.array([min_max_normalize(pair) for pair in t_pairs[i]])\n",
    "        \n",
    "        # Calculate Canberra distance after normalization\n",
    "        result = canberra(t_pair_normalized[0].flatten(), t_pair_normalized[1].flatten())  # Flatten to 1-D arrays\n",
    "        \n",
    "        if t_y[i] == 1 and result >= canberra_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result >= canberra_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result < canberra_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result < canberra_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_canberra_val = 0\n",
    "    else:\n",
    "        f1_canberra_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_canberra_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def compute_pearsonr_f1(t_pairs, t_y, pearsonr_threshold=0.3):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        # Apply min-max normalization to each pair\n",
    "        t_pair_normalized = np.array([min_max_normalize(pair) for pair in t_pairs[i]])\n",
    "        \n",
    "        # Flatten the 2-D arrays to 1-D arrays\n",
    "        t_pair_normalized_1d = t_pair_normalized[0].flatten()\n",
    "        t_pair_normalized_2d = t_pair_normalized[1].flatten()\n",
    "        \n",
    "        # Calculate the Pearson correlation coefficient\n",
    "        result, _ = pearsonr(t_pair_normalized_1d, t_pair_normalized_2d)\n",
    "        \n",
    "        if t_y[i] == 1 and abs(result) >= pearsonr_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and abs(result) >= pearsonr_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and abs(result) < pearsonr_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and abs(result) < pearsonr_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_pearsonr_val = 0\n",
    "    else:\n",
    "        f1_pearsonr_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_pearsonr_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf5e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import braycurtis\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def compute_bray_curtis_f1(t_pairs, t_y, bray_curtis_threshold=0.7):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        # Apply min-max normalization to each pair\n",
    "        t_pair_normalized = np.array([min_max_normalize(pair) for pair in t_pairs[i]])\n",
    "        \n",
    "        # Flatten the arrays to 1-D\n",
    "        t_pair_normalized_1d = t_pair_normalized[0].flatten()\n",
    "        t_pair_normalized_2d = t_pair_normalized[1].flatten()\n",
    "        \n",
    "        # Calculate the Bray-Curtis dissimilarity\n",
    "        result = braycurtis(t_pair_normalized_1d, t_pair_normalized_2d)\n",
    "        \n",
    "        if t_y[i] == 1 and result <= bray_curtis_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result <= bray_curtis_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result > bray_curtis_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result > bray_curtis_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_bray_curtis_val = 0\n",
    "    else:\n",
    "        f1_bray_curtis_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_bray_curtis_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02daea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def calculate_jaccard_similarity(set1, set2):\n",
    "    intersection = np.sum(set1 & set2)\n",
    "    union = np.sum(set1 | set2)\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "def compute_jaccard_f1(t_pairs, t_y, jaccard_threshold=0.4):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        # Apply min-max normalization to each pair\n",
    "        t_pair_normalized = np.array([min_max_normalize(pair) for pair in t_pairs[i]])\n",
    "        \n",
    "        # Flatten the arrays to 1-D and convert to binary (0 or 1)\n",
    "        t_pair_normalized_1d = (t_pair_normalized[0] >= 0.5).astype(int)\n",
    "        t_pair_normalized_2d = (t_pair_normalized[1] >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate the Jaccard similarity\n",
    "        result = calculate_jaccard_similarity(t_pair_normalized_1d, t_pair_normalized_2d)\n",
    "        \n",
    "        if t_y[i] == 1 and result >= jaccard_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result >= jaccard_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result < jaccard_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result < jaccard_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_jaccard_val = 0\n",
    "    else:\n",
    "        f1_jaccard_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_jaccard_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a20d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "def compute_hamming_f1(t_pairs, t_y, hamming_threshold=0.9):\n",
    "    cTP = 0\n",
    "    cFP = 0\n",
    "    cFN = 0\n",
    "    cTN = 0\n",
    "    \n",
    "    for i in range(np.shape(t_y)[0]):\n",
    "        # Apply min-max normalization to each pair\n",
    "        t_pair_normalized = np.array([min_max_normalize(pair) for pair in t_pairs[i]])\n",
    "        \n",
    "        # Flatten the arrays to 1-D and convert to binary (0 or 1)\n",
    "        t_pair_normalized_1d = (t_pair_normalized[0] >= 0.5).astype(int)\n",
    "        t_pair_normalized_2d = (t_pair_normalized[1] >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate Hamming distance\n",
    "        result = np.sum(t_pair_normalized_1d != t_pair_normalized_2d) / len(t_pair_normalized_1d)\n",
    "        \n",
    "        if t_y[i] == 1 and result <= hamming_threshold:\n",
    "            cTP += 1\n",
    "        elif t_y[i] != 1 and result <= hamming_threshold:\n",
    "            cFP += 1\n",
    "        elif t_y[i] == 1 and result > hamming_threshold:\n",
    "            cFN += 1\n",
    "        elif t_y[i] != 1 and result > hamming_threshold:\n",
    "            cTN += 1\n",
    "        \n",
    "    recall = cTP / (cTP + cFN) if (cTP + cFN) > 0 else 0\n",
    "    precision = cTP / (cTP + cFP) if (cTP + cFP) > 0 else 0\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f1_hamming_val = 0\n",
    "    else:\n",
    "        f1_hamming_val = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_hamming_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc0898c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TABLE_1_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TABLE_2_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TABLE_3_0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TABLE_4_0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TABLE_5_0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>TABLE_86_8</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>TABLE_87_8</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TABLE_88_8</td>\n",
       "      <td>8</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>TABLE_89_8</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>TABLE_90_8</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2    3    4    5    6    7    8    9    ...  432  433  \\\n",
       "0    TABLE_1_0    0    1    0    0    0    0    1    0    0  ...    0    0   \n",
       "1    TABLE_2_0    0    2    0    0    0    0    0    0    0  ...    0    0   \n",
       "2    TABLE_3_0    0    3    0    0    0    0    0    0    0  ...    0    0   \n",
       "3    TABLE_4_0    0    4    0    0    0    0    0    0    0  ...    0    0   \n",
       "4    TABLE_5_0    0    5    0    0    0    0    0    0    0  ...    0    0   \n",
       "..         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "85  TABLE_86_8    8   86    0    0    0    0    0    0    0  ...    0    0   \n",
       "86  TABLE_87_8    8   87    0    0    0    0    0    0    0  ...    0    0   \n",
       "87  TABLE_88_8    8   88    0    0    0    0    0    0    0  ...    0    0   \n",
       "88  TABLE_89_8    8   89    0    0    0    0    0    0    0  ...    0    0   \n",
       "89  TABLE_90_8    8   90    0    0    0    0    0    0    0  ...    0    0   \n",
       "\n",
       "    434  435  436  437  438  439  440  441  \n",
       "0     0    0    0    0    0    0    0    0  \n",
       "1     0    0    0    0    0    0    0    0  \n",
       "2     0    0    0    0    0    0    0    0  \n",
       "3     0    0    0    0    0    0    0    0  \n",
       "4     0    0    0    0    0    0    0    0  \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "85    0    0    0    0    0    0    0    0  \n",
       "86    0    0    0    0    0    0    0    0  \n",
       "87    0    0    0    0    0    0    0    0  \n",
       "88    0    0    0    0    0    0    0    0  \n",
       "89    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[90 rows x 442 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset\n",
    "df=pd.read_csv('2_case_study_no_name_new.csv',delimiter=';',header=None)\n",
    "df\n",
    "# Table names are anonymized.\n",
    "# First column: TABLE_UniqueTableNumber_ModuleNumber\n",
    "# Second column: Class number. Equal to Module Number-1. There are 12 classes in totally.\n",
    "# Third column: Unique table number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdff6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation X and Y values\n",
    "Y = df[1]\n",
    "\n",
    "Y=Y.values\n",
    "\n",
    "# Define groups for GroupKFold (using unique table numbers from column 2)\n",
    "groups = df[2].values\n",
    "\n",
    "#First three columns removed.\n",
    "X = df\n",
    "X = X.drop(0,axis=1)\n",
    "X = X.drop(1,axis=1)\n",
    "X = X.drop(2,axis=1)\n",
    "\n",
    "X=X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "870422c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-fold: 1\n",
      "(72, 439, 1)\n",
      "(439, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:6646: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(439, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ardax\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 2s 49ms/step - loss: 0.4541 - get_f1: 0.6608 - val_loss: 0.4384 - val_get_f1: 0.6667\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4196 - get_f1: 0.6595 - val_loss: 0.4024 - val_get_f1: 0.6667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3771 - get_f1: 0.6603 - val_loss: 0.3568 - val_get_f1: 0.6667\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3182 - get_f1: 0.6614 - val_loss: 0.3020 - val_get_f1: 0.6667\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2512 - get_f1: 0.6877 - val_loss: 0.2461 - val_get_f1: 0.6515\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1916 - get_f1: 0.7572 - val_loss: 0.2015 - val_get_f1: 0.6667\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1522 - get_f1: 0.8413 - val_loss: 0.1785 - val_get_f1: 0.7708\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1325 - get_f1: 0.8578 - val_loss: 0.1624 - val_get_f1: 0.7708\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1183 - get_f1: 0.8621 - val_loss: 0.1522 - val_get_f1: 0.7708\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1050 - get_f1: 0.8931 - val_loss: 0.1457 - val_get_f1: 0.7333\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0961 - get_f1: 0.9073 - val_loss: 0.1440 - val_get_f1: 0.7333\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0890 - get_f1: 0.9251 - val_loss: 0.1438 - val_get_f1: 0.7333\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0829 - get_f1: 0.9332 - val_loss: 0.1445 - val_get_f1: 0.7333\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0764 - get_f1: 0.9482 - val_loss: 0.1445 - val_get_f1: 0.9000\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0720 - get_f1: 0.9478 - val_loss: 0.1460 - val_get_f1: 0.9000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0677 - get_f1: 0.9412 - val_loss: 0.1459 - val_get_f1: nan\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0649 - get_f1: 0.9574 - val_loss: 0.1455 - val_get_f1: nan\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0614 - get_f1: 0.9624 - val_loss: 0.1462 - val_get_f1: nan\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0581 - get_f1: 0.9691 - val_loss: 0.1492 - val_get_f1: nan\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0554 - get_f1: 0.9641 - val_loss: 0.1509 - val_get_f1: nan\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "n-fold: 2\n",
      "(72, 439, 1)\n",
      "(439, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d_2 (Avera  (None, 145, 12)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_3 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 270)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(439, 1)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 42ms/step - loss: 0.4253 - get_f1: 0.6569 - val_loss: 0.4107 - val_get_f1: 0.6667\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3846 - get_f1: 0.6568 - val_loss: 0.3736 - val_get_f1: 0.6667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3392 - get_f1: 0.6542 - val_loss: 0.3397 - val_get_f1: 0.6812\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2964 - get_f1: 0.6582 - val_loss: 0.3073 - val_get_f1: 0.6667\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2544 - get_f1: 0.6511 - val_loss: 0.2794 - val_get_f1: 0.6667\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2195 - get_f1: 0.6911 - val_loss: 0.2562 - val_get_f1: 0.6667\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1919 - get_f1: 0.7256 - val_loss: 0.2350 - val_get_f1: 0.6833\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1709 - get_f1: 0.7761 - val_loss: 0.2181 - val_get_f1: 0.7018\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1578 - get_f1: 0.7650 - val_loss: 0.2015 - val_get_f1: 0.7018\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1452 - get_f1: 0.7990 - val_loss: 0.1881 - val_get_f1: 0.9000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1354 - get_f1: 0.8168 - val_loss: 0.1834 - val_get_f1: 0.9000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1255 - get_f1: 0.8292 - val_loss: 0.1768 - val_get_f1: 0.9211\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1193 - get_f1: 0.8285 - val_loss: 0.1644 - val_get_f1: 0.9444\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1123 - get_f1: 0.8456 - val_loss: 0.1589 - val_get_f1: 0.9444\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1061 - get_f1: 0.8646 - val_loss: 0.1561 - val_get_f1: 0.9444\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1019 - get_f1: 0.8514 - val_loss: 0.1505 - val_get_f1: 0.9444\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0970 - get_f1: 0.8690 - val_loss: 0.1453 - val_get_f1: 0.9444\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0921 - get_f1: 0.8844 - val_loss: 0.1404 - val_get_f1: 0.9444\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0878 - get_f1: 0.8837 - val_loss: 0.1388 - val_get_f1: 0.9444\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0847 - get_f1: 0.8806 - val_loss: 0.1353 - val_get_f1: 0.9444\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "n-fold: 3\n",
      "(72, 439, 1)\n",
      "(439, 1)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d_4 (Avera  (None, 145, 12)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_5 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 270)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(439, 1)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 42ms/step - loss: 0.4528 - get_f1: 0.6623 - val_loss: 0.4323 - val_get_f1: 0.6667\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4130 - get_f1: 0.6634 - val_loss: 0.3844 - val_get_f1: 0.6667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3566 - get_f1: 0.6591 - val_loss: 0.3288 - val_get_f1: 0.6667\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2982 - get_f1: 0.6735 - val_loss: 0.2713 - val_get_f1: 0.6812\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2349 - get_f1: 0.6793 - val_loss: 0.2176 - val_get_f1: 0.7143\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1809 - get_f1: 0.7755 - val_loss: 0.1793 - val_get_f1: 0.9000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1474 - get_f1: 0.8207 - val_loss: 0.1590 - val_get_f1: 0.9211\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1271 - get_f1: 0.8633 - val_loss: 0.1510 - val_get_f1: 0.8889\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1133 - get_f1: 0.8671 - val_loss: 0.1483 - val_get_f1: 0.9211\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1026 - get_f1: 0.9000 - val_loss: 0.1527 - val_get_f1: 0.9211\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0949 - get_f1: 0.8912 - val_loss: 0.1507 - val_get_f1: 0.9211\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0887 - get_f1: 0.8974 - val_loss: 0.1459 - val_get_f1: nan\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0838 - get_f1: 0.8999 - val_loss: 0.1451 - val_get_f1: nan\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0790 - get_f1: 0.9066 - val_loss: 0.1455 - val_get_f1: nan\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0755 - get_f1: 0.9010 - val_loss: 0.1433 - val_get_f1: nan\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0728 - get_f1: 0.9236 - val_loss: 0.1421 - val_get_f1: nan\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0695 - get_f1: 0.9346 - val_loss: 0.1435 - val_get_f1: nan\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0676 - get_f1: 0.9417 - val_loss: 0.1418 - val_get_f1: nan\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0656 - get_f1: 0.9470 - val_loss: 0.1407 - val_get_f1: nan\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0632 - get_f1: 0.9450 - val_loss: 0.1414 - val_get_f1: nan\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "n-fold: 4\n",
      "(72, 439, 1)\n",
      "(439, 1)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d_6 (Avera  (None, 145, 12)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_7 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 270)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(439, 1)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 46ms/step - loss: 0.4519 - get_f1: 0.6578 - val_loss: 0.4276 - val_get_f1: 0.6667\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4139 - get_f1: 0.6644 - val_loss: 0.3860 - val_get_f1: 0.6667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3650 - get_f1: 0.6649 - val_loss: 0.3328 - val_get_f1: 0.6667\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3069 - get_f1: 0.6562 - val_loss: 0.2735 - val_get_f1: 0.6667\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2444 - get_f1: 0.7052 - val_loss: 0.2120 - val_get_f1: 0.8478\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1977 - get_f1: 0.7502 - val_loss: 0.1615 - val_get_f1: 0.8810\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1644 - get_f1: 0.7699 - val_loss: 0.1344 - val_get_f1: 0.9211\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1478 - get_f1: 0.8374 - val_loss: 0.1191 - val_get_f1: 0.9444\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1327 - get_f1: 0.8598 - val_loss: 0.1126 - val_get_f1: 0.9706\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1203 - get_f1: 0.8739 - val_loss: 0.1130 - val_get_f1: 0.9706\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1108 - get_f1: 0.8864 - val_loss: 0.1105 - val_get_f1: 0.9706\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1037 - get_f1: 0.8875 - val_loss: 0.1084 - val_get_f1: 0.9706\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0972 - get_f1: 0.9076 - val_loss: 0.1044 - val_get_f1: 0.9706\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0925 - get_f1: 0.9234 - val_loss: 0.1023 - val_get_f1: 0.9375\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0880 - get_f1: 0.9385 - val_loss: 0.1011 - val_get_f1: 0.9667\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0846 - get_f1: 0.9312 - val_loss: 0.1001 - val_get_f1: 0.9667\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0815 - get_f1: 0.9622 - val_loss: 0.1001 - val_get_f1: 0.9667\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0791 - get_f1: 0.9586 - val_loss: 0.0979 - val_get_f1: 0.9667\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0770 - get_f1: 0.9516 - val_loss: 0.0967 - val_get_f1: 0.9667\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0736 - get_f1: 0.9590 - val_loss: 0.0994 - val_get_f1: nan\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "n-fold: 5\n",
      "(72, 439, 1)\n",
      "(439, 1)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d_8 (Avera  (None, 145, 12)           0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_9 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 270)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "(439, 1)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 37ms/step - loss: 0.4449 - get_f1: 0.6394 - val_loss: 0.4235 - val_get_f1: 0.6667\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4083 - get_f1: 0.6567 - val_loss: 0.3933 - val_get_f1: 0.6667\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3650 - get_f1: 0.6560 - val_loss: 0.3536 - val_get_f1: 0.6667\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3111 - get_f1: 0.6632 - val_loss: 0.3173 - val_get_f1: 0.6515\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2530 - get_f1: 0.7033 - val_loss: 0.2898 - val_get_f1: 0.6515\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1993 - get_f1: 0.7200 - val_loss: 0.2814 - val_get_f1: 0.6491\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1598 - get_f1: 0.7914 - val_loss: 0.2911 - val_get_f1: 0.6275\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1366 - get_f1: 0.8484 - val_loss: 0.3007 - val_get_f1: 0.6667\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1205 - get_f1: 0.8812 - val_loss: 0.2983 - val_get_f1: 0.6190\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1072 - get_f1: 0.8811 - val_loss: 0.2951 - val_get_f1: 0.6190\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0983 - get_f1: 0.8892 - val_loss: 0.2953 - val_get_f1: 0.6000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0916 - get_f1: 0.8856 - val_loss: 0.2923 - val_get_f1: 0.5476\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0854 - get_f1: 0.9127 - val_loss: 0.2965 - val_get_f1: 0.5476\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0815 - get_f1: 0.9092 - val_loss: 0.2989 - val_get_f1: 0.5476\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0779 - get_f1: 0.9072 - val_loss: 0.3041 - val_get_f1: 0.5476\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0752 - get_f1: 0.9219 - val_loss: 0.3096 - val_get_f1: 0.5476\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0725 - get_f1: 0.9156 - val_loss: 0.3086 - val_get_f1: 0.5476\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0696 - get_f1: 0.9313 - val_loss: 0.3137 - val_get_f1: 0.5476\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0677 - get_f1: 0.9378 - val_loss: 0.3178 - val_get_f1: 0.5476\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0656 - get_f1: 0.9420 - val_loss: 0.3236 - val_get_f1: 0.5476\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Siamese Neural Network Training & Validation Step (Process Group 1)\n",
    "\n",
    "\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "cvTrainscores = []\n",
    "cvTestscores = []\n",
    "cvi=0\n",
    "\n",
    "cvTrainscoresCosine = []\n",
    "cvTestscoresCosine = []\n",
    "\n",
    "cvTrainscoresManhattan = []\n",
    "cvTestscoresManhattan = []\n",
    "\n",
    "\n",
    "cvTrainscoresEuclidean = []\n",
    "cvTestscoresEuclidean = []\n",
    "\n",
    "cvTrainscoresPearsonR = []\n",
    "cvTestscoresPearsonR = []\n",
    "\n",
    "cvTrainscoresBrayCurtis = []\n",
    "cvTestscoresBrayCurtis = []\n",
    "\n",
    "cvTrainscoresJaccard = []\n",
    "cvTestscoresJaccard= []\n",
    "\n",
    "cvTrainscoresHamming = []\n",
    "cvTestscoresHamming = []\n",
    "\n",
    "cvTrainscoresCanberra = []\n",
    "cvTestscoresCanberra = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X, Y, groups):\n",
    "\n",
    "    cvi=cvi+1\n",
    "    print(\"n-fold: \"+str(cvi))\n",
    "    \n",
    "    x_train = X[train]\n",
    "    x_test = X[test]\n",
    "    y_train = Y[train]\n",
    "    y_test = Y[test]\n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0], 439, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 439, 1)\n",
    "    input_shape = (439, 1)\n",
    "    print(x_train.shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    input_shape = (439,1)\n",
    "    \n",
    "    print(input_shape)\n",
    "    \n",
    "    # create training+test positive and negative pairs\n",
    "    digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "    tr_pairs, tr_y = create_pairs_new3(x_train, digit_indices)\n",
    "    \n",
    "    digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "    te_pairs, te_y = create_pairs_new3(x_test, digit_indices)\n",
    "    \n",
    "    # network definition\n",
    "    base_network = create_base_net_new2(input_shape)\n",
    "    \n",
    "    print(input_shape)\n",
    "\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    \n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclid_dis,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    \n",
    "    model = Model([input_a, input_b], distance)\n",
    "\n",
    "    #train\n",
    "    model.compile(loss=contrastive_loss, optimizer='adam', metrics=[get_f1])\n",
    "\n",
    "    model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=16,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "    \n",
    "    # compute final accuracy on training and test sets for n-fold\n",
    "    p=2\n",
    "    y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "    tr_acc = compute_f1(tr_y, y_pred)\n",
    "    tr_f1_cosine = compute_cosine_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_manhattan = compute_manhattan_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_euclidean = compute_euclidean_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_pearsonr = compute_pearsonr_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_braycurtis = compute_bray_curtis_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_hamming = compute_hamming_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_jaccard = compute_jaccard_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "    tr_f1_canberra = compute_canberra_f1(tr_pairs,tr_y)  # Uses default threshold\n",
    "\n",
    "    y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "    te_acc = compute_f1(te_y, y_pred)\n",
    "    te_f1_cosine = compute_cosine_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_manhattan = compute_manhattan_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_euclidean = compute_euclidean_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_pearsonr = compute_pearsonr_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_braycurtis = compute_bray_curtis_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_hamming = compute_hamming_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_jaccard = compute_jaccard_f1(te_pairs,te_y)  # Uses default threshold\n",
    "    te_f1_canberra = compute_canberra_f1(te_pairs,te_y)  # Uses default threshold\n",
    "\n",
    "    cvTrainscores.append(100 * tr_acc)\n",
    "    cvTestscores.append(100 * te_acc)\n",
    "\n",
    "    cvTrainscoresCosine.append(100 * tr_f1_cosine)\n",
    "    cvTestscoresCosine.append(100 * te_f1_cosine)\n",
    "\n",
    "    cvTrainscoresManhattan.append(100 * tr_f1_manhattan)\n",
    "    cvTestscoresManhattan.append(100 * te_f1_manhattan)\n",
    "\n",
    "    cvTrainscoresEuclidean.append(100 * tr_f1_euclidean)\n",
    "    cvTestscoresEuclidean.append(100 * te_f1_euclidean)\n",
    "\n",
    "    cvTrainscoresPearsonR.append(100 * tr_f1_pearsonr)\n",
    "    cvTestscoresPearsonR.append(100 * te_f1_pearsonr)\n",
    "\n",
    "    cvTrainscoresBrayCurtis.append(100 * tr_f1_braycurtis)\n",
    "    cvTestscoresBrayCurtis.append(100 * te_f1_braycurtis)\n",
    "\n",
    "\n",
    "    cvTrainscoresJaccard.append(100 * tr_f1_jaccard)\n",
    "    cvTestscoresJaccard.append(100 * te_f1_jaccard)\n",
    "\n",
    "    cvTrainscoresHamming.append(100 * tr_f1_hamming)\n",
    "    cvTestscoresHamming.append(100 * te_f1_hamming)\n",
    "    \n",
    "    cvTrainscoresCanberra.append(100 * tr_f1_canberra)\n",
    "    cvTestscoresCanberra.append(100 * te_f1_canberra)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d7dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese Cross Validation F1 Result:\n",
      "Train: 94.40% (+/- 2.41%)\n",
      "Test: 77.38% (+/- 15.57%)\n",
      "Cosine Cross Validation F1 Result:\n",
      "Train: 82.73% (+/- 2.31%)\n",
      "Test: 80.33% (+/- 8.01%)\n",
      "Manhahttan Cross Validation F1 Result:\n",
      "Train: 66.67% (+/- 0.00%)\n",
      "Test: 66.67% (+/- 0.00%)\n",
      "Euclidean Cross Validation F1 Result:\n",
      "Train: 66.67% (+/- 0.00%)\n",
      "Test: 66.67% (+/- 0.00%)\n",
      "Bray-Curtis Cross Validation F1 Result:\n",
      "Train: 83.06% (+/- 0.86%)\n",
      "Test: 81.22% (+/- 4.55%)\n",
      "PearsonR Cross Validation F1 Result:\n",
      "Train: 81.80% (+/- 0.51%)\n",
      "Test: 81.22% (+/- 4.55%)\n",
      "Jaccard Cross Validation F1 Result:\n",
      "Train: 57.58% (+/- 2.61%)\n",
      "Test: 49.23% (+/- 19.56%)\n",
      "Hamming Cross Validation F1 Result:\n",
      "Train: 66.67% (+/- 0.00%)\n",
      "Test: 66.67% (+/- 0.00%)\n",
      "Canberra Cross Validation F1 Result:\n",
      "Train: 66.67% (+/- 0.00%)\n",
      "Test: 66.67% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Print final F1 Score accuracy on training and test sets based on Cross Validation\n",
    "print(\"Siamese Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscores), np.std(cvTrainscores)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscores), np.std(cvTestscores)))\n",
    "\n",
    "print(\"Cosine Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresCosine), np.std(cvTrainscoresCosine)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresCosine), np.std(cvTestscoresCosine)))\n",
    "\n",
    "print(\"Manhahttan Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresManhattan), np.std(cvTrainscoresManhattan)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresManhattan), np.std(cvTestscoresManhattan)))\n",
    "\n",
    "print(\"Euclidean Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresEuclidean), np.std(cvTrainscoresEuclidean)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresEuclidean), np.std(cvTestscoresEuclidean)))\n",
    "\n",
    "print(\"Bray-Curtis Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresBrayCurtis), np.std(cvTrainscoresBrayCurtis)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresBrayCurtis), np.std(cvTestscoresBrayCurtis)))\n",
    "\n",
    "print(\"PearsonR Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresPearsonR), np.std(cvTrainscoresPearsonR)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresPearsonR), np.std(cvTestscoresPearsonR)))\n",
    "\n",
    "print(\"Jaccard Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresJaccard), np.std(cvTrainscoresJaccard)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresJaccard), np.std(cvTestscoresJaccard)))\n",
    "\n",
    "print(\"Hamming Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresHamming), np.std(cvTrainscoresHamming)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresHamming), np.std(cvTestscoresHamming)))\n",
    "\n",
    "print(\"Canberra Cross Validation F1 Result:\")\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresCanberra), np.std(cvTrainscoresCanberra)))\n",
    "print(\"Test: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresCanberra), np.std(cvTestscoresCanberra)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d92ca343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "F1 SCORE RANKING (Sorted by Test Performance)\n",
      "================================================================================\n",
      "Rank  Method       Train Mean   Train Std    Test Mean    Test Std    \n",
      "--------------------------------------------------------------------------------\n",
      "1     PearsonR     84.3510      1.8065       81.7698      7.4289      \n",
      "2     Cosine       83.2008      2.1579       81.4510      7.2389      \n",
      "3     Bray-Curtis  84.7506      1.1585       81.0079      7.7594      \n",
      "4     Siamese      95.3863      0.8330       78.9412      8.5787      \n",
      "5     Manhattan    66.6667      0.0000       66.6667      0.0000      \n",
      "6     Euclidean    66.6667      0.0000       66.6667      0.0000      \n",
      "7     Hamming      66.6667      0.0000       66.6667      0.0000      \n",
      "8     Canberra     66.6667      0.0000       66.6667      0.0000      \n",
      "9     Jaccard      56.3202      5.0800       54.5255      12.1794     \n",
      "\n",
      "================================================================================\n",
      "TOP 3 METHODS BY TEST F1 SCORE:\n",
      "================================================================================\n",
      "1. PearsonR: 81.7698 ± 7.4289\n",
      "2. Cosine: 81.4510 ± 7.2389\n",
      "3. Bray-Curtis: 81.0079 ± 7.7594\n",
      "\n",
      "================================================================================\n",
      "BEST PERFORMING METHOD:\n",
      "================================================================================\n",
      "Method: PearsonR\n",
      "Test F1 Score: 81.7698 ± 7.4289\n",
      "Train F1 Score: 84.3510 ± 1.8065\n"
     ]
    }
   ],
   "source": [
    "# F1 Score Results Summary and Ranking\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all F1 scores\n",
    "f1_results = {\n",
    "    'Method': ['Siamese', 'Cosine', 'Manhattan', 'Euclidean', 'Bray-Curtis', 'PearsonR', 'Jaccard', 'Hamming', 'Canberra'],\n",
    "    'Train_Mean': [np.mean(cvTrainscores), np.mean(cvTrainscoresCosine), np.mean(cvTrainscoresManhattan), \n",
    "                   np.mean(cvTrainscoresEuclidean), np.mean(cvTrainscoresBrayCurtis), np.mean(cvTrainscoresPearsonR),\n",
    "                   np.mean(cvTrainscoresJaccard), np.mean(cvTrainscoresHamming), np.mean(cvTrainscoresCanberra)],\n",
    "    'Train_Std': [np.std(cvTrainscores), np.std(cvTrainscoresCosine), np.std(cvTrainscoresManhattan),\n",
    "                  np.std(cvTrainscoresEuclidean), np.std(cvTrainscoresBrayCurtis), np.std(cvTrainscoresPearsonR),\n",
    "                  np.std(cvTrainscoresJaccard), np.std(cvTrainscoresHamming), np.std(cvTrainscoresCanberra)],\n",
    "    'Test_Mean': [np.mean(cvTestscores), np.mean(cvTestscoresCosine), np.mean(cvTestscoresManhattan),\n",
    "                  np.mean(cvTestscoresEuclidean), np.mean(cvTestscoresBrayCurtis), np.mean(cvTestscoresPearsonR),\n",
    "                  np.mean(cvTestscoresJaccard), np.mean(cvTestscoresHamming), np.mean(cvTestscoresCanberra)],\n",
    "    'Test_Std': [np.std(cvTestscores), np.std(cvTestscoresCosine), np.std(cvTestscoresManhattan),\n",
    "                 np.std(cvTestscoresEuclidean), np.std(cvTestscoresBrayCurtis), np.std(cvTestscoresPearsonR),\n",
    "                 np.std(cvTestscoresJaccard), np.std(cvTestscoresHamming), np.std(cvTestscoresCanberra)]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(f1_results)\n",
    "\n",
    "# Sort by Test Mean F1 Score (descending)\n",
    "df_sorted = df_results.sort_values('Test_Mean', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"F1 SCORE RANKING (Sorted by Test Performance)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<5} {'Method':<12} {'Train Mean':<12} {'Train Std':<12} {'Test Mean':<12} {'Test Std':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, row in df_sorted.iterrows():\n",
    "    print(f\"{i+1:<5} {row['Method']:<12} {row['Train_Mean']:<12.4f} {row['Train_Std']:<12.4f} {row['Test_Mean']:<12.4f} {row['Test_Std']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 3 METHODS BY TEST F1 SCORE:\")\n",
    "print(\"=\"*80)\n",
    "for i in range(min(3, len(df_sorted))):\n",
    "    method = df_sorted.iloc[i]['Method']\n",
    "    test_mean = df_sorted.iloc[i]['Test_Mean']\n",
    "    test_std = df_sorted.iloc[i]['Test_Std']\n",
    "    print(f\"{i+1}. {method}: {test_mean:.4f} ± {test_std:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST PERFORMING METHOD:\")\n",
    "print(\"=\"*80)\n",
    "best_method = df_sorted.iloc[0]\n",
    "print(f\"Method: {best_method['Method']}\")\n",
    "print(f\"Test F1 Score: {best_method['Test_Mean']:.4f} ± {best_method['Test_Std']:.4f}\")\n",
    "print(f\"Train F1 Score: {best_method['Train_Mean']:.4f} ± {best_method['Train_Std']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa55309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity metrics threshold values: 21 values (0.0-1.0)\n",
      "Distance metrics threshold values: 21 values (0.0-50.0)\n",
      "Euclidean threshold values: 21 values (0.0-10.0)\n",
      "Threshold values and results storage initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Threshold Analysis Setup - Fixed for Different Metric Types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define different threshold ranges for different metric types\n",
    "# Similarity metrics (0-1 range): Cosine, PearsonR, BrayCurtis, Jaccard, Hamming\n",
    "similarity_thresholds = np.arange(0, 1.05, 0.05)\n",
    "\n",
    "# Distance metrics (0-50 range): Manhattan, Canberra  \n",
    "distance_thresholds = np.arange(0, 51, 2.5)\n",
    "\n",
    "# Euclidean distance (0-10 range)\n",
    "euclidean_thresholds = np.arange(0, 10.5, 0.5)\n",
    "\n",
    "print(f\"Similarity metrics threshold values: {len(similarity_thresholds)} values (0.0-1.0)\")\n",
    "print(f\"Distance metrics threshold values: {len(distance_thresholds)} values (0.0-50.0)\")\n",
    "print(f\"Euclidean threshold values: {len(euclidean_thresholds)} values (0.0-10.0)\")\n",
    "\n",
    "# Results storage for all metrics\n",
    "threshold_results = {\n",
    "    'Cosine': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Manhattan': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Euclidean': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'PearsonR': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'BrayCurtis': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Jaccard': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Hamming': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Canberra': {'thresholds': [], 'train_f1': [], 'test_f1': []}\n",
    "}\n",
    "\n",
    "print(\"Threshold values and results storage initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "085a966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE THRESHOLD ANALYSIS RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "COSINE METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Cosine:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.0000      \n",
      "2.00         0.0000      \n",
      "3.00         0.0000      \n",
      "4.00         0.0000      \n",
      "5.00         0.0000      \n",
      "6.00         0.0000      \n",
      "7.00         0.0000      \n",
      "8.00         0.0000      \n",
      "9.00         0.0000      \n",
      "10.00        0.0000      \n",
      "11.00        0.0000      \n",
      "12.00        0.0000      \n",
      "13.00        0.0000      \n",
      "14.00        0.0000      \n",
      "15.00        0.0000      \n",
      "16.00        0.0000      \n",
      "17.00        0.0000      \n",
      "18.00        0.0000      \n",
      "19.00        0.0000      \n",
      "20.00        0.0000      \n",
      "21.00        0.0000      \n",
      "22.00        0.0000      \n",
      "23.00        0.0000      \n",
      "24.00        0.0000      \n",
      "25.00        0.0000      \n",
      "26.00        0.0000      \n",
      "27.00        0.0000      \n",
      "28.00        0.0000      \n",
      "29.00        0.0000      \n",
      "30.00        0.0000      \n",
      "31.00        0.0000      \n",
      "32.00        0.0000      \n",
      "33.00        0.0000      \n",
      "34.00        0.0000      \n",
      "35.00        0.0000      \n",
      "36.00        0.0000      \n",
      "37.00        0.0000      \n",
      "38.00        0.0000      \n",
      "39.00        0.0000      \n",
      "40.00        0.0000      \n",
      "\n",
      "MANHATTAN METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Manhattan:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.6667      \n",
      "2.00         0.6667      \n",
      "3.00         0.6667      \n",
      "4.00         0.6462      \n",
      "5.00         0.6462      \n",
      "6.00         0.6333      \n",
      "7.00         0.6195      \n",
      "8.00         0.5923      \n",
      "9.00         0.5859      \n",
      "10.00        0.5441      \n",
      "11.00        0.4697      \n",
      "12.00        0.4865      \n",
      "13.00        0.4904      \n",
      "14.00        0.4339      \n",
      "15.00        0.3950      \n",
      "16.00        0.3540      \n",
      "17.00        0.3296      \n",
      "18.00        0.2782      \n",
      "19.00        0.2710      \n",
      "20.00        0.2088      \n",
      "21.00        0.2386      \n",
      "22.00        0.1769      \n",
      "23.00        0.1947      \n",
      "24.00        0.2220      \n",
      "25.00        0.2347      \n",
      "26.00        0.1476      \n",
      "27.00        0.1486      \n",
      "28.00        0.1698      \n",
      "29.00        0.1308      \n",
      "30.00        0.0750      \n",
      "31.00        0.0905      \n",
      "32.00        0.0879      \n",
      "33.00        0.1564      \n",
      "34.00        0.1256      \n",
      "35.00        0.1312      \n",
      "36.00        0.1041      \n",
      "37.00        0.0533      \n",
      "38.00        0.1282      \n",
      "39.00        0.0364      \n",
      "40.00        0.0600      \n",
      "\n",
      "EUCLIDEAN METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Euclidean:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.6667      \n",
      "2.00         0.6667      \n",
      "3.00         0.5617      \n",
      "4.00         0.4017      \n",
      "5.00         0.1299      \n",
      "6.00         0.0671      \n",
      "7.00         0.0000      \n",
      "8.00         0.0000      \n",
      "9.00         0.0000      \n",
      "10.00        0.0000      \n",
      "11.00        0.0000      \n",
      "12.00        0.0000      \n",
      "13.00        0.0000      \n",
      "14.00        0.0000      \n",
      "15.00        0.0000      \n",
      "16.00        0.0000      \n",
      "17.00        0.0000      \n",
      "18.00        0.0000      \n",
      "19.00        0.0000      \n",
      "20.00        0.0000      \n",
      "21.00        0.0000      \n",
      "22.00        0.0000      \n",
      "23.00        0.0000      \n",
      "24.00        0.0000      \n",
      "25.00        0.0000      \n",
      "26.00        0.0000      \n",
      "27.00        0.0000      \n",
      "28.00        0.0000      \n",
      "29.00        0.0000      \n",
      "30.00        0.0000      \n",
      "31.00        0.0000      \n",
      "32.00        0.0000      \n",
      "33.00        0.0000      \n",
      "34.00        0.0000      \n",
      "35.00        0.0000      \n",
      "36.00        0.0000      \n",
      "37.00        0.0000      \n",
      "38.00        0.0000      \n",
      "39.00        0.0000      \n",
      "40.00        0.0000      \n",
      "\n",
      "PEARSONR METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for PearsonR:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.0000      \n",
      "2.00         0.0000      \n",
      "3.00         0.0000      \n",
      "4.00         0.0000      \n",
      "5.00         0.0000      \n",
      "6.00         0.0000      \n",
      "7.00         0.0000      \n",
      "8.00         0.0000      \n",
      "9.00         0.0000      \n",
      "10.00        0.0000      \n",
      "11.00        0.0000      \n",
      "12.00        0.0000      \n",
      "13.00        0.0000      \n",
      "14.00        0.0000      \n",
      "15.00        0.0000      \n",
      "16.00        0.0000      \n",
      "17.00        0.0000      \n",
      "18.00        0.0000      \n",
      "19.00        0.0000      \n",
      "20.00        0.0000      \n",
      "21.00        0.0000      \n",
      "22.00        0.0000      \n",
      "23.00        0.0000      \n",
      "24.00        0.0000      \n",
      "25.00        0.0000      \n",
      "26.00        0.0000      \n",
      "27.00        0.0000      \n",
      "28.00        0.0000      \n",
      "29.00        0.0000      \n",
      "30.00        0.0000      \n",
      "31.00        0.0000      \n",
      "32.00        0.0000      \n",
      "33.00        0.0000      \n",
      "34.00        0.0000      \n",
      "35.00        0.0000      \n",
      "36.00        0.0000      \n",
      "37.00        0.0000      \n",
      "38.00        0.0000      \n",
      "39.00        0.0000      \n",
      "40.00        0.0000      \n",
      "\n",
      "BRAYCURTIS METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 1.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for BrayCurtis:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.0000      \n",
      "1.00         0.6667      \n",
      "2.00         0.6667      \n",
      "3.00         0.6667      \n",
      "4.00         0.6667      \n",
      "5.00         0.6667      \n",
      "6.00         0.6667      \n",
      "7.00         0.6667      \n",
      "8.00         0.6667      \n",
      "9.00         0.6667      \n",
      "10.00        0.6667      \n",
      "11.00        0.6667      \n",
      "12.00        0.6667      \n",
      "13.00        0.6667      \n",
      "14.00        0.6667      \n",
      "15.00        0.6667      \n",
      "16.00        0.6667      \n",
      "17.00        0.6667      \n",
      "18.00        0.6667      \n",
      "19.00        0.6667      \n",
      "20.00        0.6667      \n",
      "21.00        0.6667      \n",
      "22.00        0.6667      \n",
      "23.00        0.6667      \n",
      "24.00        0.6667      \n",
      "25.00        0.6667      \n",
      "26.00        0.6667      \n",
      "27.00        0.6667      \n",
      "28.00        0.6667      \n",
      "29.00        0.6667      \n",
      "30.00        0.6667      \n",
      "31.00        0.6667      \n",
      "32.00        0.6667      \n",
      "33.00        0.6667      \n",
      "34.00        0.6667      \n",
      "35.00        0.6667      \n",
      "36.00        0.6667      \n",
      "37.00        0.6667      \n",
      "38.00        0.6667      \n",
      "39.00        0.6667      \n",
      "40.00        0.6667      \n",
      "\n",
      "JACCARD METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Jaccard:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.0000      \n",
      "2.00         0.0000      \n",
      "3.00         0.0000      \n",
      "4.00         0.0000      \n",
      "5.00         0.0000      \n",
      "6.00         0.0000      \n",
      "7.00         0.0000      \n",
      "8.00         0.0000      \n",
      "9.00         0.0000      \n",
      "10.00        0.0000      \n",
      "11.00        0.0000      \n",
      "12.00        0.0000      \n",
      "13.00        0.0000      \n",
      "14.00        0.0000      \n",
      "15.00        0.0000      \n",
      "16.00        0.0000      \n",
      "17.00        0.0000      \n",
      "18.00        0.0000      \n",
      "19.00        0.0000      \n",
      "20.00        0.0000      \n",
      "21.00        0.0000      \n",
      "22.00        0.0000      \n",
      "23.00        0.0000      \n",
      "24.00        0.0000      \n",
      "25.00        0.0000      \n",
      "26.00        0.0000      \n",
      "27.00        0.0000      \n",
      "28.00        0.0000      \n",
      "29.00        0.0000      \n",
      "30.00        0.0000      \n",
      "31.00        0.0000      \n",
      "32.00        0.0000      \n",
      "33.00        0.0000      \n",
      "34.00        0.0000      \n",
      "35.00        0.0000      \n",
      "36.00        0.0000      \n",
      "37.00        0.0000      \n",
      "38.00        0.0000      \n",
      "39.00        0.0000      \n",
      "40.00        0.0000      \n",
      "\n",
      "HAMMING METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 1.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Hamming:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.0000      \n",
      "1.00         0.6667      \n",
      "2.00         0.6667      \n",
      "3.00         0.6667      \n",
      "4.00         0.6667      \n",
      "5.00         0.6667      \n",
      "6.00         0.6667      \n",
      "7.00         0.6667      \n",
      "8.00         0.6667      \n",
      "9.00         0.6667      \n",
      "10.00        0.6667      \n",
      "11.00        0.6667      \n",
      "12.00        0.6667      \n",
      "13.00        0.6667      \n",
      "14.00        0.6667      \n",
      "15.00        0.6667      \n",
      "16.00        0.6667      \n",
      "17.00        0.6667      \n",
      "18.00        0.6667      \n",
      "19.00        0.6667      \n",
      "20.00        0.6667      \n",
      "21.00        0.6667      \n",
      "22.00        0.6667      \n",
      "23.00        0.6667      \n",
      "24.00        0.6667      \n",
      "25.00        0.6667      \n",
      "26.00        0.6667      \n",
      "27.00        0.6667      \n",
      "28.00        0.6667      \n",
      "29.00        0.6667      \n",
      "30.00        0.6667      \n",
      "31.00        0.6667      \n",
      "32.00        0.6667      \n",
      "33.00        0.6667      \n",
      "34.00        0.6667      \n",
      "35.00        0.6667      \n",
      "36.00        0.6667      \n",
      "37.00        0.6667      \n",
      "38.00        0.6667      \n",
      "39.00        0.6667      \n",
      "40.00        0.6667      \n",
      "\n",
      "CANBERRA METRIC RESULTS:\n",
      "------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Canberra:\n",
      "Threshold    Test F1     \n",
      "-------------------------\n",
      "0.00         0.6667      \n",
      "1.00         0.6667      \n",
      "2.00         0.6667      \n",
      "3.00         0.6667      \n",
      "4.00         0.6462      \n",
      "5.00         0.6462      \n",
      "6.00         0.6333      \n",
      "7.00         0.6195      \n",
      "8.00         0.5923      \n",
      "9.00         0.5859      \n",
      "10.00        0.5441      \n",
      "11.00        0.4697      \n",
      "12.00        0.4865      \n",
      "13.00        0.4904      \n",
      "14.00        0.4339      \n",
      "15.00        0.3950      \n",
      "16.00        0.3540      \n",
      "17.00        0.3296      \n",
      "18.00        0.2782      \n",
      "19.00        0.2710      \n",
      "20.00        0.2088      \n",
      "21.00        0.2386      \n",
      "22.00        0.1769      \n",
      "23.00        0.1947      \n",
      "24.00        0.2220      \n",
      "25.00        0.2347      \n",
      "26.00        0.1476      \n",
      "27.00        0.1486      \n",
      "28.00        0.1698      \n",
      "29.00        0.1308      \n",
      "30.00        0.0750      \n",
      "31.00        0.0905      \n",
      "32.00        0.0879      \n",
      "33.00        0.1564      \n",
      "34.00        0.1256      \n",
      "35.00        0.1312      \n",
      "36.00        0.1041      \n",
      "37.00        0.0533      \n",
      "38.00        0.1282      \n",
      "39.00        0.0364      \n",
      "40.00        0.0600      \n",
      "\n",
      "====================================================================================================\n",
      "OVERALL BEST PERFORMANCE BY METRIC\n",
      "====================================================================================================\n",
      "Rank   Metric       Best Threshold  Test F1     \n",
      "--------------------------------------------------\n",
      "1      Cosine       0.00            0.6667      \n",
      "2      Manhattan    0.00            0.6667      \n",
      "3      Euclidean    0.00            0.6667      \n",
      "4      PearsonR     0.00            0.6667      \n",
      "5      BrayCurtis   1.00            0.6667      \n",
      "6      Jaccard      0.00            0.6667      \n",
      "7      Hamming      1.00            0.6667      \n",
      "8      Canberra     0.00            0.6667      \n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY\n",
      "====================================================================================================\n",
      "Total threshold values tested: 41\n",
      "Threshold range: 0.00 to 40.00\n",
      "Step size: 1.00\n",
      "Total metrics tested: 8\n",
      "Best overall metric: Cosine\n",
      "Best overall threshold: 0.00\n",
      "Best overall test F1: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Display Comprehensive Results for All Thresholds and Metrics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE THRESHOLD ANALYSIS RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Create detailed results table\n",
    "results_data = []\n",
    "\n",
    "for metric_name in threshold_results.keys():\n",
    "    thresholds = threshold_results[metric_name]['thresholds']\n",
    "    train_f1s = threshold_results[metric_name]['train_f1']\n",
    "    test_f1s = threshold_results[metric_name]['test_f1']\n",
    "    \n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        results_data.append({\n",
    "            'Metric': metric_name,\n",
    "            'Threshold': threshold,\n",
    "            'Train_F1': train_f1s[i],\n",
    "            'Test_F1': test_f1s[i]\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_threshold_results = pd.DataFrame(results_data)\n",
    "\n",
    "# Display results for each metric\n",
    "for metric_name in threshold_results.keys():\n",
    "    print(f\"\\n{metric_name.upper()} METRIC RESULTS:\")\n",
    "    print(\"-\" * 60)\n",
    "    metric_data = df_threshold_results[df_threshold_results['Metric'] == metric_name]\n",
    "    \n",
    "    # Find best threshold for this metric\n",
    "    best_idx = metric_data['Test_F1'].idxmax()\n",
    "    best_threshold = metric_data.loc[best_idx, 'Threshold']\n",
    "    best_test_f1 = metric_data.loc[best_idx, 'Test_F1']\n",
    "    best_train_f1 = metric_data.loc[best_idx, 'Train_F1']\n",
    "    \n",
    "    print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "    print(f\"Best Test F1: {best_test_f1:.4f}\")\n",
    "    print(f\"Best Train F1: {best_train_f1:.4f}\")\n",
    "    \n",
    "    # Show all thresholds for this metric\n",
    "    print(f\"\\nAll Thresholds for {metric_name}:\")\n",
    "    print(f\"{'Threshold':<12} {'Test F1':<12}\")\n",
    "    print(\"-\" * 25)\n",
    "    for _, row in metric_data.iterrows():\n",
    "        print(f\"{row['Threshold']:<12.2f} {row['Test_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"OVERALL BEST PERFORMANCE BY METRIC\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find best performance for each metric\n",
    "best_performances = []\n",
    "for metric_name in threshold_results.keys():\n",
    "    metric_data = df_threshold_results[df_threshold_results['Metric'] == metric_name]\n",
    "    best_idx = metric_data['Test_F1'].idxmax()\n",
    "    best_performances.append({\n",
    "        'Metric': metric_name,\n",
    "        'Best_Threshold': metric_data.loc[best_idx, 'Threshold'],\n",
    "        'Best_Test_F1': metric_data.loc[best_idx, 'Test_F1'],\n",
    "        'Best_Train_F1': metric_data.loc[best_idx, 'Train_F1']\n",
    "    })\n",
    "\n",
    "# Sort by best test F1 score\n",
    "best_performances_df = pd.DataFrame(best_performances)\n",
    "best_performances_df = best_performances_df.sort_values('Best_Test_F1', ascending=False)\n",
    "\n",
    "print(f\"{'Rank':<6} {'Metric':<12} {'Best Threshold':<15} {'Test F1':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for i, (_, row) in enumerate(best_performances_df.iterrows()):\n",
    "    print(f\"{i+1:<6} {row['Metric']:<12} {row['Best_Threshold']:<15.2f} {row['Best_Test_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Total threshold values tested: {len(threshold_values)}\")\n",
    "print(f\"Threshold range: {threshold_values[0]:.2f} to {threshold_values[-1]:.2f}\")\n",
    "print(f\"Step size: {threshold_values[1] - threshold_values[0]:.2f}\")\n",
    "print(f\"Total metrics tested: {len(threshold_results)}\")\n",
    "print(f\"Best overall metric: {best_performances_df.iloc[0]['Metric']}\")\n",
    "print(f\"Best overall threshold: {best_performances_df.iloc[0]['Best_Threshold']:.2f}\")\n",
    "print(f\"Best overall test F1: {best_performances_df.iloc[0]['Best_Test_F1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb319572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FIXED SIAMESE NETWORK TRAINING\n",
      "================================================================================\n",
      "Random seeds set for reproducibility:\n",
      "• NumPy seed: 42\n",
      "• Python random seed: 42\n",
      "• TensorFlow seed: 42\n",
      "\n",
      "Training Siamese Network with fixed parameters:\n",
      "• Epochs: 20\n",
      "• Batch size: 16\n",
      "• Cross-validation: 5-fold\n",
      "• Random state: 42\n",
      "\n",
      "Fold 1/5:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "  Train F1: 0.9677 (96.77%)\n",
      "  Test F1:  0.9000 (90.00%)\n",
      "\n",
      "Fold 2/5:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "  Train F1: 0.9677 (96.77%)\n",
      "  Test F1:  0.8889 (88.89%)\n",
      "\n",
      "Fold 3/5:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "  Train F1: 0.9677 (96.77%)\n",
      "  Test F1:  0.7143 (71.43%)\n",
      "\n",
      "Fold 4/5:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "  Train F1: 0.9385 (93.85%)\n",
      "  Test F1:  0.8000 (80.00%)\n",
      "\n",
      "Fold 5/5:\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 439, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 439, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 437, 12)           48        \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 145, 12)           0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 143, 8)            296       \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 47, 8)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 45, 6)             150       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 2439      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2933 (11.46 KB)\n",
      "Trainable params: 2933 (11.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "  Train F1: 0.9385 (93.85%)\n",
      "  Test F1:  0.7778 (77.78%)\n",
      "\n",
      "================================================================================\n",
      "FIXED SIAMESE NETWORK RESULTS\n",
      "================================================================================\n",
      "Train: 95.60% (+/- 1.43%)\n",
      "Test:  81.62% (+/- 6.99%)\n",
      "\n",
      "Comparison with Original Results:\n",
      "Original - Train: 95.90% (+/- 1.29%), Test: 82.84% (+/- 9.77%)\n",
      "Fixed    - Train: 95.60% (+/- 1.43%), Test: 81.62% (+/- 6.99%)\n"
     ]
    }
   ],
   "source": [
    "# Fixed Siamese Network Training - Single Training with Fixed Seed\n",
    "print(\"=\"*80)\n",
    "print(\"FIXED SIAMESE NETWORK TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Set fixed random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Random seeds set for reproducibility:\")\n",
    "print(\"• NumPy seed: 42\")\n",
    "print(\"• Python random seed: 42\") \n",
    "print(\"• TensorFlow seed: 42\")\n",
    "\n",
    "# Clear any existing model state\n",
    "K.clear_session()\n",
    "\n",
    "# Siamese Network Training with Fixed Parameters\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cvTrainscoresSiamese = []\n",
    "cvTestscoresSiamese = []\n",
    "\n",
    "print(f\"\\nTraining Siamese Network with fixed parameters:\")\n",
    "print(f\"• Epochs: {epochs}\")\n",
    "print(f\"• Batch size: 16\")\n",
    "print(f\"• Cross-validation: 5-fold\")\n",
    "print(f\"• Random state: 42\")\n",
    "\n",
    "cvi = 0\n",
    "for train, test in kfold.split(X, Y):\n",
    "    cvi += 1\n",
    "    print(f\"\\nFold {cvi}/5:\")\n",
    "    \n",
    "    # Prepare data\n",
    "    x_train = X[train]\n",
    "    x_test = X[test]\n",
    "    y_train = Y[train]\n",
    "    y_test = Y[test]\n",
    "    \n",
    "    x_train = x_train.reshape(x_train.shape[0], 439, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 439, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    \n",
    "    # Create pairs\n",
    "    digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "    tr_pairs, tr_y = create_pairs_new3(x_train, digit_indices)\n",
    "    \n",
    "    digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "    te_pairs, te_y = create_pairs_new3(x_test, digit_indices)\n",
    "    \n",
    "    # Create fresh model for each fold\n",
    "    base_network = create_base_net_new2((439, 1))\n",
    "    input_a = Input(shape=(439, 1))\n",
    "    input_b = Input(shape=(439, 1))\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    distance = Lambda(euclid_dis, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    model = Model([input_a, input_b], distance)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=contrastive_loss, optimizer='adam', metrics=[get_f1])\n",
    "    \n",
    "    # Train model\n",
    "    model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "              batch_size=16,\n",
    "              epochs=epochs,\n",
    "              validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y),\n",
    "              verbose=0)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred_train = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "    y_pred_test = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "    \n",
    "    tr_acc = compute_f1(tr_y, y_pred_train)\n",
    "    te_acc = compute_f1(te_y, y_pred_test)\n",
    "    \n",
    "    cvTrainscoresSiamese.append(100 * tr_acc)\n",
    "    cvTestscoresSiamese.append(100 * te_acc)\n",
    "    \n",
    "    print(f\"  Train F1: {tr_acc:.4f} ({100 * tr_acc:.2f}%)\")\n",
    "    print(f\"  Test F1:  {te_acc:.4f} ({100 * te_acc:.2f}%)\")\n",
    "    \n",
    "    # Clear model to free memory\n",
    "    del model\n",
    "    K.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED SIAMESE NETWORK RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresSiamese), np.std(cvTrainscoresSiamese)))\n",
    "print(\"Test:  %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresSiamese), np.std(cvTestscoresSiamese)))\n",
    "\n",
    "print(\"\\nComparison with Original Results:\")\n",
    "print(\"Original - Train: 95.90% (+/- 1.29%), Test: 82.84% (+/- 9.77%)\")\n",
    "print(\"Fixed    - Train: %.2f%% (+/- %.2f%%), Test: %.2f%% (+/- %.2f%%)\" % \n",
    "      (np.mean(cvTrainscoresSiamese), np.std(cvTrainscoresSiamese),\n",
    "       np.mean(cvTestscoresSiamese), np.std(cvTestscoresSiamese)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZED THRESHOLD ANALYSIS - DISTANCE METRICS ONLY\n",
      "================================================================================\n",
      "Testing distance metrics only (no Siamese training):\n",
      "• Threshold values: 21 (0.0 to 40.0)\n",
      "• Cross-validation: 5-fold with fixed seed\n",
      "• Focus: Distance metrics threshold optimization\n",
      "\n",
      "Testing threshold: 0.00\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.05\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.10\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.15\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.20\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.25\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.30\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.35\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.40\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.45\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.50\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.55\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.60\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.65\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.70\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.75\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.80\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.85\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.90\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 0.95\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold: 1.00\n",
      "--------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "================================================================================\n",
      "Distance metrics threshold analysis completed!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Optimized Threshold Analysis - Distance Metrics Only (No Siamese)\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZED THRESHOLD ANALYSIS - DISTANCE METRICS ONLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Clear any existing state\n",
    "K.clear_session()\n",
    "\n",
    "# Set fixed random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Use the same cross-validation setup as before\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Results storage for distance metrics only\n",
    "distance_threshold_results = {\n",
    "    'Cosine': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Manhattan': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Euclidean': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'PearsonR': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'BrayCurtis': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Jaccard': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Hamming': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Canberra': {'thresholds': [], 'train_f1': [], 'test_f1': []}\n",
    "}\n",
    "\n",
    "print(\"Testing distance metrics only (no Siamese training):\")\n",
    "print(f\"• Threshold values: {len(threshold_values)} (0.00 to 1.00)\")\n",
    "print(\"• Cross-validation: 5-fold with fixed seed\")\n",
    "print(\"• Focus: Distance metrics threshold optimization\")\n",
    "\n",
    "# Test each threshold value\n",
    "for threshold in threshold_values:\n",
    "    print(f\"\\nTesting threshold: {threshold:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Initialize lists for this threshold\n",
    "    train_scores = {'Cosine': [], 'Manhattan': [], 'Euclidean': [], 'PearsonR': [], \n",
    "                   'BrayCurtis': [], 'Jaccard': [], 'Hamming': [], 'Canberra': []}\n",
    "    test_scores = {'Cosine': [], 'Manhattan': [], 'Euclidean': [], 'PearsonR': [], \n",
    "                  'BrayCurtis': [], 'Jaccard': [], 'Hamming': [], 'Canberra': []}\n",
    "    \n",
    "    cvi = 0\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        cvi += 1\n",
    "        print(f\"  Fold {cvi}/5\", end=\" \")\n",
    "        \n",
    "        # Prepare data (same as before)\n",
    "        x_train = X[train]\n",
    "        x_test = X[test]\n",
    "        y_train = Y[train]\n",
    "        y_test = Y[test]\n",
    "        \n",
    "        x_train = x_train.reshape(x_train.shape[0], 439, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 439, 1)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        y_train = y_train.astype('float32')\n",
    "        y_test = y_test.astype('float32')\n",
    "        \n",
    "        # Create pairs\n",
    "        digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "        tr_pairs, tr_y = create_pairs_new3(x_train, digit_indices)\n",
    "        \n",
    "        digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "        te_pairs, te_y = create_pairs_new3(x_test, digit_indices)\n",
    "        \n",
    "        # Test distance metrics with current threshold (NO SIAMESE TRAINING)\n",
    "        metrics_functions = {\n",
    "            'Cosine': compute_cosine_f1,\n",
    "            'Manhattan': compute_manhattan_f1,\n",
    "            'Euclidean': compute_euclidean_f1,\n",
    "            'PearsonR': compute_pearsonr_f1,\n",
    "            'BrayCurtis': compute_bray_curtis_f1,\n",
    "            'Jaccard': compute_jaccard_f1,\n",
    "            'Hamming': compute_hamming_f1,\n",
    "            'Canberra': compute_canberra_f1\n",
    "        }\n",
    "        \n",
    "        for metric_name, metric_func in metrics_functions.items():\n",
    "            # Train scores\n",
    "            train_f1 = metric_func(tr_pairs, tr_y, threshold)\n",
    "            train_scores[metric_name].append(train_f1)\n",
    "            \n",
    "            # Test scores\n",
    "            test_f1 = metric_func(te_pairs, te_y, threshold)\n",
    "            test_scores[metric_name].append(test_f1)\n",
    "    \n",
    "    # Store results for this threshold\n",
    "    for metric_name in train_scores.keys():\n",
    "        distance_threshold_results[metric_name]['thresholds'].append(threshold)\n",
    "        distance_threshold_results[metric_name]['train_f1'].append(np.mean(train_scores[metric_name]))\n",
    "        distance_threshold_results[metric_name]['test_f1'].append(np.mean(test_scores[metric_name]))\n",
    "    \n",
    "    print(\"✓\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Distance metrics threshold analysis completed!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ba6018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPREHENSIVE RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "1. SIAMESE NETWORK (Fixed Training):\n",
      "--------------------------------------------------\n",
      "Train: 95.60% (+/- 1.43%)\n",
      "Test:  81.62% (+/- 6.99%)\n",
      "\n",
      "2. DISTANCE METRICS - OPTIMAL THRESHOLDS:\n",
      "--------------------------------------------------\n",
      "Rank   Metric       Best Threshold  Test F1     \n",
      "--------------------------------------------------\n",
      "1      PearsonR     0.25            0.8549      \n",
      "2      Cosine       0.40            0.8421      \n",
      "3      Jaccard      0.20            0.8300      \n",
      "4      BrayCurtis   0.75            0.8065      \n",
      "5      Hamming      0.05            0.7235      \n",
      "6      Manhattan    0.00            0.6667      \n",
      "7      Euclidean    0.00            0.6667      \n",
      "8      Canberra     0.00            0.6667      \n",
      "\n",
      "3. OVERALL RANKING (Including Siamese):\n",
      "--------------------------------------------------\n",
      "Rank   Method       Best Threshold  Test F1     \n",
      "--------------------------------------------------\n",
      "1      PearsonR     0.25            0.8549      \n",
      "2      Cosine       0.40            0.8421      \n",
      "3      Jaccard      0.20            0.8300      \n",
      "4      Siamese      N/A             0.8162      \n",
      "5      BrayCurtis   0.75            0.8065      \n",
      "6      Hamming      0.05            0.7235      \n",
      "7      Manhattan    0.00            0.6667      \n",
      "8      Euclidean    0.00            0.6667      \n",
      "9      Canberra     0.00            0.6667      \n",
      "\n",
      "4. SUMMARY:\n",
      "--------------------------------------------------\n",
      "• Siamese Network: 81.62% test F1 (baseline)\n",
      "• Best Distance Metric: PearsonR with 0.25 threshold\n",
      "• Best Distance F1: 0.8549\n",
      "• Performance Gap: -0.0387\n",
      "\n",
      "====================================================================================================\n",
      "ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display Final Results - Siamese + Optimized Distance Metrics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL COMPREHENSIVE RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. SIAMESE NETWORK (Fixed Training):\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Train: %.2f%% (+/- %.2f%%)\" % (np.mean(cvTrainscoresSiamese), np.std(cvTrainscoresSiamese)))\n",
    "print(\"Test:  %.2f%% (+/- %.2f%%)\" % (np.mean(cvTestscoresSiamese), np.std(cvTestscoresSiamese)))\n",
    "\n",
    "print(\"\\n2. DISTANCE METRICS - OPTIMAL THRESHOLDS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create detailed results table for distance metrics\n",
    "distance_results_data = []\n",
    "\n",
    "for metric_name in distance_threshold_results.keys():\n",
    "    thresholds = distance_threshold_results[metric_name]['thresholds']\n",
    "    train_f1s = distance_threshold_results[metric_name]['train_f1']\n",
    "    test_f1s = distance_threshold_results[metric_name]['test_f1']\n",
    "    \n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        distance_results_data.append({\n",
    "            'Metric': metric_name,\n",
    "            'Threshold': threshold,\n",
    "            'Train_F1': train_f1s[i],\n",
    "            'Test_F1': test_f1s[i]\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_distance_results = pd.DataFrame(distance_results_data)\n",
    "\n",
    "# Find best performance for each distance metric\n",
    "best_distance_performances = []\n",
    "for metric_name in distance_threshold_results.keys():\n",
    "    metric_data = df_distance_results[df_distance_results['Metric'] == metric_name]\n",
    "    best_idx = metric_data['Test_F1'].idxmax()\n",
    "    best_distance_performances.append({\n",
    "        'Metric': metric_name,\n",
    "        'Best_Threshold': metric_data.loc[best_idx, 'Threshold'],\n",
    "        'Best_Test_F1': metric_data.loc[best_idx, 'Test_F1'],\n",
    "        'Best_Train_F1': metric_data.loc[best_idx, 'Train_F1']\n",
    "    })\n",
    "\n",
    "# Sort by best test F1 score\n",
    "best_distance_performances_df = pd.DataFrame(best_distance_performances)\n",
    "best_distance_performances_df = best_distance_performances_df.sort_values('Best_Test_F1', ascending=False)\n",
    "\n",
    "print(f\"{'Rank':<6} {'Metric':<12} {'Best Threshold':<15} {'Test F1':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for i, (_, row) in enumerate(best_distance_performances_df.iterrows()):\n",
    "    print(f\"{i+1:<6} {row['Metric']:<12} {row['Best_Threshold']:<15.2f} {row['Best_Test_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n3. OVERALL RANKING (Including Siamese):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Add Siamese to the ranking\n",
    "overall_results = []\n",
    "overall_results.append({\n",
    "    'Method': 'Siamese',\n",
    "    'Best_Threshold': 'N/A',\n",
    "    'Best_Test_F1': np.mean(cvTestscoresSiamese) / 100,  # Convert to 0-1 scale\n",
    "    'Best_Train_F1': np.mean(cvTrainscoresSiamese) / 100\n",
    "})\n",
    "\n",
    "# Add distance metrics\n",
    "for _, row in best_distance_performances_df.iterrows():\n",
    "    overall_results.append({\n",
    "        'Method': row['Metric'],\n",
    "        'Best_Threshold': row['Best_Threshold'],\n",
    "        'Best_Test_F1': row['Best_Test_F1'],\n",
    "        'Best_Train_F1': row['Best_Train_F1']\n",
    "    })\n",
    "\n",
    "# Sort by test F1 score\n",
    "overall_results_df = pd.DataFrame(overall_results)\n",
    "overall_results_df = overall_results_df.sort_values('Best_Test_F1', ascending=False)\n",
    "\n",
    "print(f\"{'Rank':<6} {'Method':<12} {'Best Threshold':<15} {'Test F1':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for i, (_, row) in enumerate(overall_results_df.iterrows()):\n",
    "    threshold_str = f\"{row['Best_Threshold']:.2f}\" if row['Best_Threshold'] != 'N/A' else 'N/A'\n",
    "    print(f\"{i+1:<6} {row['Method']:<12} {threshold_str:<15} {row['Best_Test_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n4. SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Siamese Network: {np.mean(cvTestscoresSiamese):.2f}% test F1 (baseline)\")\n",
    "print(f\"• Best Distance Metric: {best_distance_performances_df.iloc[0]['Metric']} with {best_distance_performances_df.iloc[0]['Best_Threshold']:.2f} threshold\")\n",
    "print(f\"• Best Distance F1: {best_distance_performances_df.iloc[0]['Best_Test_F1']:.4f}\")\n",
    "print(f\"• Performance Gap: {np.mean(cvTestscoresSiamese)/100 - best_distance_performances_df.iloc[0]['Best_Test_F1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a325c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE THRESHOLD TESTING - ALL METRICS\n",
      "================================================================================\n",
      "Testing 21 threshold values: 0.00 to 1.00\n",
      "Testing 8 metrics: ['Cosine', 'Manhattan', 'Euclidean', 'PearsonR', 'BrayCurtis', 'Jaccard', 'Hamming', 'Canberra']\n",
      "Cross-validation: 5-fold\n",
      "\n",
      "Testing threshold 1/21: 0.00\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 2/21: 0.05\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 3/21: 0.10\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 4/21: 0.15\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 5/21: 0.20\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 6/21: 0.25\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 7/21: 0.30\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 8/21: 0.35\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 9/21: 0.40\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 10/21: 0.45\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 11/21: 0.50\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 12/21: 0.55\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 13/21: 0.60\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 14/21: 0.65\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 15/21: 0.70\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 16/21: 0.75\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 17/21: 0.80\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 18/21: 0.85\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 19/21: 0.90\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 20/21: 0.95\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "Testing threshold 21/21: 1.00\n",
      "------------------------------------------------------------\n",
      "  Fold 1/5   Fold 2/5   Fold 3/5   Fold 4/5   Fold 5/5 ✓\n",
      "\n",
      "================================================================================\n",
      "THRESHOLD TESTING COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Threshold Testing for All Metrics\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE THRESHOLD TESTING - ALL METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Clear any existing state\n",
    "K.clear_session()\n",
    "\n",
    "# Cross-validation setup\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Results storage\n",
    "threshold_results = {\n",
    "    'Cosine': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Manhattan': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Euclidean': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'PearsonR': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'BrayCurtis': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Jaccard': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Hamming': {'thresholds': [], 'train_f1': [], 'test_f1': []},\n",
    "    'Canberra': {'thresholds': [], 'train_f1': [], 'test_f1': []}\n",
    "}\n",
    "\n",
    "# Metric functions\n",
    "metrics_functions = {\n",
    "    'Cosine': compute_cosine_f1,\n",
    "    'Manhattan': compute_manhattan_f1,\n",
    "    'Euclidean': compute_euclidean_f1,\n",
    "    'PearsonR': compute_pearsonr_f1,\n",
    "    'BrayCurtis': compute_bray_curtis_f1,\n",
    "    'Jaccard': compute_jaccard_f1,\n",
    "    'Hamming': compute_hamming_f1,\n",
    "    'Canberra': compute_canberra_f1\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(threshold_values)} threshold values: {threshold_values[0]:.2f} to {threshold_values[-1]:.2f}\")\n",
    "print(f\"Testing {len(metrics_functions)} metrics: {list(metrics_functions.keys())}\")\n",
    "print(f\"Cross-validation: 5-fold\")\n",
    "\n",
    "# Test each threshold value\n",
    "for threshold_idx, threshold in enumerate(threshold_values):\n",
    "    print(f\"\\nTesting threshold {threshold_idx+1}/{len(threshold_values)}: {threshold:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Initialize lists for this threshold\n",
    "    train_scores = {metric: [] for metric in metrics_functions.keys()}\n",
    "    test_scores = {metric: [] for metric in metrics_functions.keys()}\n",
    "    \n",
    "    cvi = 0\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        cvi += 1\n",
    "        print(f\"  Fold {cvi}/5\", end=\" \")\n",
    "        \n",
    "        # Prepare data\n",
    "        x_train = X[train]\n",
    "        x_test = X[test]\n",
    "        y_train = Y[train]\n",
    "        y_test = Y[test]\n",
    "        \n",
    "        x_train = x_train.reshape(x_train.shape[0], 439, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 439, 1)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        y_train = y_train.astype('float32')\n",
    "        y_test = y_test.astype('float32')\n",
    "        \n",
    "        # Create pairs\n",
    "        digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "        tr_pairs, tr_y = create_pairs_new3(x_train, digit_indices)\n",
    "        \n",
    "        digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "        te_pairs, te_y = create_pairs_new3(x_test, digit_indices)\n",
    "        \n",
    "        # Test each metric with current threshold\n",
    "        for metric_name, metric_func in metrics_functions.items():\n",
    "            # Train scores\n",
    "            train_f1 = metric_func(tr_pairs, tr_y, threshold)\n",
    "            train_scores[metric_name].append(train_f1)\n",
    "            \n",
    "            # Test scores\n",
    "            test_f1 = metric_func(te_pairs, te_y, threshold)\n",
    "            test_scores[metric_name].append(test_f1)\n",
    "    \n",
    "    # Store results for this threshold\n",
    "    for metric_name in metrics_functions.keys():\n",
    "        threshold_results[metric_name]['thresholds'].append(threshold)\n",
    "        threshold_results[metric_name]['train_f1'].append(np.mean(train_scores[metric_name]))\n",
    "        threshold_results[metric_name]['test_f1'].append(np.mean(test_scores[metric_name]))\n",
    "    \n",
    "    print(\"✓\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THRESHOLD TESTING COMPLETED!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc4b2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE THRESHOLD ANALYSIS RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "DETAILED RESULTS BY METRIC:\n",
      "====================================================================================================\n",
      "\n",
      "COSINE METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.40\n",
      "Best Test F1: 0.8421\n",
      "Best Train F1: 0.8200\n",
      "\n",
      "All Thresholds for Cosine:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.6790       0.6773      \n",
      "0.10         0.7440       0.7636      \n",
      "0.15         0.7866       0.7720      \n",
      "0.20         0.8172       0.8203      \n",
      "0.25         0.8245       0.8379      \n",
      "0.30         0.8282       0.8183      \n",
      "0.35         0.8127       0.8260      \n",
      "0.40         0.8200       0.8421      \n",
      "0.45         0.7765       0.7776      \n",
      "0.50         0.7486       0.6712      \n",
      "0.55         0.6824       0.5888      \n",
      "0.60         0.5475       0.4548      \n",
      "0.65         0.3809       0.2194      \n",
      "0.70         0.3304       0.2218      \n",
      "0.75         0.2032       0.0800      \n",
      "0.80         0.1248       0.0000      \n",
      "0.85         0.0311       0.0000      \n",
      "0.90         0.0000       0.0000      \n",
      "0.95         0.0000       0.0000      \n",
      "1.00         0.0000       0.0000      \n",
      "\n",
      "MANHATTAN METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Manhattan:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.6667       0.6667      \n",
      "0.10         0.6667       0.6667      \n",
      "0.15         0.6667       0.6667      \n",
      "0.20         0.6667       0.6667      \n",
      "0.25         0.6667       0.6667      \n",
      "0.30         0.6667       0.6667      \n",
      "0.35         0.6667       0.6667      \n",
      "0.40         0.6667       0.6667      \n",
      "0.45         0.6674       0.6667      \n",
      "0.50         0.6667       0.6667      \n",
      "0.55         0.6667       0.6667      \n",
      "0.60         0.6667       0.6667      \n",
      "0.65         0.6667       0.6667      \n",
      "0.70         0.6667       0.6667      \n",
      "0.75         0.6667       0.6667      \n",
      "0.80         0.6667       0.6667      \n",
      "0.85         0.6667       0.6667      \n",
      "0.90         0.6667       0.6667      \n",
      "0.95         0.6667       0.6667      \n",
      "1.00         0.6667       0.6667      \n",
      "\n",
      "EUCLIDEAN METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Euclidean:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.6667       0.6667      \n",
      "0.10         0.6667       0.6667      \n",
      "0.15         0.6667       0.6667      \n",
      "0.20         0.6667       0.6667      \n",
      "0.25         0.6667       0.6667      \n",
      "0.30         0.6667       0.6667      \n",
      "0.35         0.6667       0.6667      \n",
      "0.40         0.6667       0.6667      \n",
      "0.45         0.6674       0.6667      \n",
      "0.50         0.6667       0.6667      \n",
      "0.55         0.6667       0.6667      \n",
      "0.60         0.6667       0.6667      \n",
      "0.65         0.6667       0.6667      \n",
      "0.70         0.6667       0.6667      \n",
      "0.75         0.6667       0.6667      \n",
      "0.80         0.6667       0.6667      \n",
      "0.85         0.6667       0.6667      \n",
      "0.90         0.6667       0.6667      \n",
      "0.95         0.6667       0.6667      \n",
      "1.00         0.6667       0.6667      \n",
      "\n",
      "PEARSONR METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.25\n",
      "Best Test F1: 0.8549\n",
      "Best Train F1: 0.8300\n",
      "\n",
      "All Thresholds for PearsonR:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.7137       0.6987      \n",
      "0.10         0.7611       0.7910      \n",
      "0.15         0.8006       0.7930      \n",
      "0.20         0.8280       0.8233      \n",
      "0.25         0.8300       0.8549      \n",
      "0.30         0.8185       0.8419      \n",
      "0.35         0.8146       0.8322      \n",
      "0.40         0.7864       0.8158      \n",
      "0.45         0.7573       0.7483      \n",
      "0.50         0.7397       0.6004      \n",
      "0.55         0.6482       0.5418      \n",
      "0.60         0.5147       0.4608      \n",
      "0.65         0.3828       0.2194      \n",
      "0.70         0.2380       0.1491      \n",
      "0.75         0.1983       0.0800      \n",
      "0.80         0.0672       0.0000      \n",
      "0.85         0.0311       0.0000      \n",
      "0.90         0.0000       0.0000      \n",
      "0.95         0.0000       0.0000      \n",
      "1.00         0.0000       0.0000      \n",
      "\n",
      "BRAYCURTIS METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.75\n",
      "Best Test F1: 0.8065\n",
      "Best Train F1: 0.8121\n",
      "\n",
      "All Thresholds for BrayCurtis:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.0000       0.0000      \n",
      "0.05         0.0000       0.0000      \n",
      "0.10         0.0000       0.0000      \n",
      "0.15         0.0123       0.0000      \n",
      "0.20         0.1248       0.0000      \n",
      "0.25         0.2037       0.0800      \n",
      "0.30         0.3128       0.1927      \n",
      "0.35         0.3817       0.2255      \n",
      "0.40         0.5380       0.4537      \n",
      "0.45         0.6794       0.5888      \n",
      "0.50         0.7438       0.6324      \n",
      "0.55         0.7686       0.7760      \n",
      "0.60         0.7888       0.7858      \n",
      "0.65         0.8079       0.7741      \n",
      "0.70         0.8224       0.8013      \n",
      "0.75         0.8121       0.8065      \n",
      "0.80         0.8070       0.7974      \n",
      "0.85         0.7877       0.7987      \n",
      "0.90         0.7467       0.7158      \n",
      "0.95         0.6760       0.6821      \n",
      "1.00         0.6667       0.6667      \n",
      "\n",
      "JACCARD METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.20\n",
      "Best Test F1: 0.8300\n",
      "Best Train F1: 0.8025\n",
      "\n",
      "All Thresholds for Jaccard:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.7343       0.7270      \n",
      "0.10         0.8009       0.8046      \n",
      "0.15         0.8264       0.7847      \n",
      "0.20         0.8025       0.8300      \n",
      "0.25         0.8032       0.7946      \n",
      "0.30         0.7682       0.7287      \n",
      "0.35         0.7179       0.5964      \n",
      "0.40         0.5848       0.4984      \n",
      "0.45         0.4425       0.3182      \n",
      "0.50         0.3789       0.2218      \n",
      "0.55         0.2395       0.1527      \n",
      "0.60         0.1994       0.0800      \n",
      "0.65         0.1248       0.0000      \n",
      "0.70         0.0672       0.0000      \n",
      "0.75         0.0123       0.0000      \n",
      "0.80         0.0063       0.0000      \n",
      "0.85         0.0000       0.0000      \n",
      "0.90         0.0000       0.0000      \n",
      "0.95         0.0000       0.0000      \n",
      "1.00         0.0000       0.0000      \n",
      "\n",
      "HAMMING METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.05\n",
      "Best Test F1: 0.7235\n",
      "Best Train F1: 0.7364\n",
      "\n",
      "All Thresholds for Hamming:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.0000       0.0000      \n",
      "0.05         0.7364       0.7235      \n",
      "0.10         0.6867       0.6776      \n",
      "0.15         0.6667       0.6718      \n",
      "0.20         0.6667       0.6667      \n",
      "0.25         0.6667       0.6667      \n",
      "0.30         0.6667       0.6667      \n",
      "0.35         0.6667       0.6667      \n",
      "0.40         0.6667       0.6667      \n",
      "0.45         0.6667       0.6667      \n",
      "0.50         0.6667       0.6667      \n",
      "0.55         0.6667       0.6667      \n",
      "0.60         0.6667       0.6667      \n",
      "0.65         0.6667       0.6667      \n",
      "0.70         0.6667       0.6667      \n",
      "0.75         0.6667       0.6667      \n",
      "0.80         0.6667       0.6667      \n",
      "0.85         0.6667       0.6667      \n",
      "0.90         0.6667       0.6667      \n",
      "0.95         0.6667       0.6667      \n",
      "1.00         0.6667       0.6667      \n",
      "\n",
      "CANBERRA METRIC RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Best Threshold: 0.00\n",
      "Best Test F1: 0.6667\n",
      "Best Train F1: 0.6667\n",
      "\n",
      "All Thresholds for Canberra:\n",
      "Threshold    Train F1     Test F1     \n",
      "----------------------------------------\n",
      "0.00         0.6667       0.6667      \n",
      "0.05         0.6667       0.6667      \n",
      "0.10         0.6667       0.6667      \n",
      "0.15         0.6667       0.6667      \n",
      "0.20         0.6667       0.6667      \n",
      "0.25         0.6667       0.6667      \n",
      "0.30         0.6667       0.6667      \n",
      "0.35         0.6667       0.6667      \n",
      "0.40         0.6667       0.6667      \n",
      "0.45         0.6674       0.6667      \n",
      "0.50         0.6667       0.6667      \n",
      "0.55         0.6667       0.6667      \n",
      "0.60         0.6667       0.6667      \n",
      "0.65         0.6667       0.6667      \n",
      "0.70         0.6667       0.6667      \n",
      "0.75         0.6667       0.6667      \n",
      "0.80         0.6667       0.6667      \n",
      "0.85         0.6667       0.6667      \n",
      "0.90         0.6667       0.6667      \n",
      "0.95         0.6667       0.6667      \n",
      "1.00         0.6667       0.6667      \n",
      "\n",
      "====================================================================================================\n",
      "OVERALL BEST PERFORMANCE BY METRIC\n",
      "====================================================================================================\n",
      "Rank   Metric       Best Threshold  Test F1      Train F1    \n",
      "----------------------------------------------------------------------\n",
      "1      PearsonR     0.25            0.8549       0.8300      \n",
      "2      Cosine       0.40            0.8421       0.8200      \n",
      "3      Jaccard      0.20            0.8300       0.8025      \n",
      "4      BrayCurtis   0.75            0.8065       0.8121      \n",
      "5      Hamming      0.05            0.7235       0.7364      \n",
      "6      Manhattan    0.00            0.6667       0.6667      \n",
      "7      Euclidean    0.00            0.6667       0.6667      \n",
      "8      Canberra     0.00            0.6667       0.6667      \n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY\n",
      "====================================================================================================\n",
      "Total threshold values tested: 21\n",
      "Threshold range: 0.00 to 1.00\n",
      "Step size: 0.05\n",
      "Total metrics tested: 8\n",
      "Best overall metric: PearsonR\n",
      "Best overall threshold: 0.25\n",
      "Best overall test F1: 0.8549\n",
      "\n",
      "====================================================================================================\n",
      "ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display Comprehensive Results for All Thresholds and Metrics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE THRESHOLD ANALYSIS RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Create detailed results table\n",
    "results_data = []\n",
    "\n",
    "for metric_name in threshold_results.keys():\n",
    "    thresholds = threshold_results[metric_name]['thresholds']\n",
    "    train_f1s = threshold_results[metric_name]['train_f1']\n",
    "    test_f1s = threshold_results[metric_name]['test_f1']\n",
    "    \n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        results_data.append({\n",
    "            'Metric': metric_name,\n",
    "            'Threshold': threshold,\n",
    "            'Train_F1': train_f1s[i],\n",
    "            'Test_F1': test_f1s[i]\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_threshold_results = pd.DataFrame(results_data)\n",
    "\n",
    "# Display results for each metric\n",
    "print(\"\\nDETAILED RESULTS BY METRIC:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for metric_name in threshold_results.keys():\n",
    "    print(f\"\\n{metric_name.upper()} METRIC RESULTS:\")\n",
    "    print(\"-\" * 80)\n",
    "    metric_data = df_threshold_results[df_threshold_results['Metric'] == metric_name]\n",
    "    \n",
    "    # Find best threshold for this metric\n",
    "    best_idx = metric_data['Test_F1'].idxmax()\n",
    "    best_threshold = metric_data.loc[best_idx, 'Threshold']\n",
    "    best_test_f1 = metric_data.loc[best_idx, 'Test_F1']\n",
    "    best_train_f1 = metric_data.loc[best_idx, 'Train_F1']\n",
    "    \n",
    "    print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "    print(f\"Best Test F1: {best_test_f1:.4f}\")\n",
    "    print(f\"Best Train F1: {best_train_f1:.4f}\")\n",
    "    \n",
    "    # Show all thresholds for this metric\n",
    "    print(f\"\\nAll Thresholds for {metric_name}:\")\n",
    "    print(f\"{'Threshold':<12} {'Train F1':<12} {'Test F1':<12}\")\n",
    "    print(\"-\" * 40)\n",
    "    for _, row in metric_data.iterrows():\n",
    "        print(f\"{row['Threshold']:<12.2f} {row['Train_F1']:<12.4f} {row['Test_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"OVERALL BEST PERFORMANCE BY METRIC\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find best performance for each metric\n",
    "best_performances = []\n",
    "for metric_name in threshold_results.keys():\n",
    "    metric_data = df_threshold_results[df_threshold_results['Metric'] == metric_name]\n",
    "    best_idx = metric_data['Test_F1'].idxmax()\n",
    "    best_performances.append({\n",
    "        'Metric': metric_name,\n",
    "        'Best_Threshold': metric_data.loc[best_idx, 'Threshold'],\n",
    "        'Best_Test_F1': metric_data.loc[best_idx, 'Test_F1'],\n",
    "        'Best_Train_F1': metric_data.loc[best_idx, 'Train_F1']\n",
    "    })\n",
    "\n",
    "# Sort by best test F1 score\n",
    "best_performances_df = pd.DataFrame(best_performances)\n",
    "best_performances_df = best_performances_df.sort_values('Best_Test_F1', ascending=False)\n",
    "\n",
    "print(f\"{'Rank':<6} {'Metric':<12} {'Best Threshold':<15} {'Test F1':<12} {'Train F1':<12}\")\n",
    "print(\"-\" * 70)\n",
    "for i, (_, row) in enumerate(best_performances_df.iterrows()):\n",
    "    print(f\"{i+1:<6} {row['Metric']:<12} {row['Best_Threshold']:<15.2f} {row['Best_Test_F1']:<12.4f} {row['Best_Train_F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Total threshold values tested: {len(threshold_values)}\")\n",
    "print(f\"Threshold range: {threshold_values[0]:.2f} to {threshold_values[-1]:.2f}\")\n",
    "print(f\"Step size: {threshold_values[1] - threshold_values[0]:.2f}\")\n",
    "print(f\"Total metrics tested: {len(threshold_results)}\")\n",
    "print(f\"Best overall metric: {best_performances_df.iloc[0]['Metric']}\")\n",
    "print(f\"Best overall threshold: {best_performances_df.iloc[0]['Best_Threshold']:.2f}\")\n",
    "print(f\"Best overall test F1: {best_performances_df.iloc[0]['Best_Test_F1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
